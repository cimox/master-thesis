\chapter{Analytické úlohy nad prúdom dát}
\label{Analytické úlohy v prúde dát}
Spracovanie, analýza a dolovanie dát predstavuje vo všeobecnosti výzvu. Zvláštnu pozornosť si tieto úlohy vyžadujú pri spracovaní, analýze a dolovaní z prúdu udalostí. Prúd udalostí je často nazývaný \textit{prúd dát} alebo \textit{údajov}, či len skrátene \textit{prúd}. V tomto texte budeme pre jednoduchosť používať najmä termín \textit{prúd} a \textit{prúd dát}. Avšak v literatúre sa môžu vyskytnúť aj termíny ako \textit{prúd udalostí}, \textit{sekvencia udalostí, či elementov}, pričom všetky termíny majú v tomto texte \textit{rovnaký} význam. 
\par
\begin{definition}{Prúd je potenciálne nekonečná sekvencia elementov \citep{tran2014change}.}
\begin{align*}
	S = \{(X_1,T_1), ..., (X_j,T_j), ...\}
\end{align*}
Kde každý element je pár $(X_j,T_j)$ kde $X_j$ je d-dimenzionálny vektor $X_j = (x_1, x_2, ..., x_d)$ prichádzajúci v čase $T_j$. $T_j$ je často nazývaný aj časová pečiatka, existujú dva typy časovej pečiatky: explicitná je generovaná keď dáta dorazia, implicitná je priradená vektoru v čase ich vzniku.
\end{definition}

% Vseobecny popis toho preco je potrebne prudove spracovanie dat
Takmer každé odvetvie, napríklad telekomunikačné siete alebo predajné reťazce, je dnes zdrojom masívnych objemov dát. Vzhľadom na ich veľký objem analytyci a doménoví experti často strácajú možnosť dolovať v celej sade dát. Zvykom preto býva použiť distribuované paradigmy a umožniť tak dolovanie v celej kolekcii dát, čo je ale náročné na vývoj a čas spracovania. Stáva sa preto častým zvykom, že sa vyberie reprezentatívna vzorka, ktorej spracovanie predstavuje menšiu časovú a pamäťovú výzvu. Pri pamäťovej a výpočtovej náročnosti hovoríme o hardvérových limitoch počítača, pričom ak hovoríme o časovej náročnosti hovoríme o limitovanom čase doménového experta (čakanie na výsledok analýzy) \citep{hulten2001mining}. Predpokladajme, že bude pre doménoveho experta vysokým prínosom možnosť vykonávať analýzy nad prúdom v reálnom čase. Výstupy z takejto analýzy sú na rôznej granularite a úrovni, pričom môžu byť neskôr použité na ďalšie spracovanie alebo na priame prezentovanie výsledkov.
\par
Problém analýzy dát bol veľmi dobre a podrobne študovaný pri spracovaní statickej kolekcie údajov. Pri tomto prístupe sú všetky dáta v pamäti počítača. Vybraný algoritmus potom môže pomerne jednoducho prečítať celú množinu niekoľkokrát s cieľom zvýšenia presnosti a kvality výsledného modelu. Tento prístup nie je aplikovateľný v doméne prúdov dát z nasledujúcich dôvodov:
\begin{itemize}
	\item \textit{Prúd dát je potenciálne nekonečná sekvencia udalostí}, ktoré môžu byť správne alebo chybne usporiadané v závislosti od spoľahlivosti zdroja dát. Hlavný problém tu predstavuje to, že prúd je nekonečná sekvencia udalostí. Závažnosť problému usporiadania daných udalostí, či vozriek závisí od konkrétnej úlohy analýzy prúdu dát.
	\item \textit{Obmedzená pamäť} značí, že nie je možné všetky dáta zbierať a ukladať do pamäti. Toto obmedzenie vyplýva z prvej vlastnosti prúdov dát.
	\item \textit{Model pre klasifikáciu prúdov musí byť ihneď pripravený k použitiu.} Znamená to, že hneď po tom ako sú spracované prvé dáta z prúdu je model pripravený na použitie, napríklad klasifikovať iný prúd dát.
	\item \textit{Prúdy dát takmer vždy v sebe nesú zmeny} (angl. concept drift), na ktoré sa musí vedieť klasifikátor adaptovať. Vlasnosť klasifikačných modelov vysporiadať sa so zmenami považujeme za rozhodujúcu pri hodnotení ich kvality a použiteľnosti v praxi. Preto sa aj nami navrhovaná metóda sústreďuje na vytvorenie metódy schopnej adaptácie na zmeny a ich adekvátne interpretovanie používateľovi. Zmeny v dátach môžu byť náhle, postupné ale môžu predstavovať aj očakávané sezónne vplyvy (napr. obdobie Vianoc z pohľadu počtu nákupov internetového obchodu).
\end{itemize}

% Vyskumne vyzvy v prudoch dat vseobecne
Analýza a spracovanie prúdov dát pridáva viaceré otvorené výzvy a možnosti pre výskum \citep{krempl2014open}:
\begin{itemize}
	\item \textit{Ochrana súkromia a dôvernosti} pri analýze a dolovaní v prúde dát. Hlavným cieľom je vyvinúť metódy a techniky odhaľujúce informácie a vzory, ktoré by znížili dôveryhodnosť a povinnosti ochrania súkromia. Dve hlavné výzvy pri analýze a dolovaní v prúdoch dát sú: \textit{vysporiadanie sa s neúplnými dátami} a \textit{uchovanie zmien (angl. concept drift) v prúde dát}. Neúplné dáta môžu začať prichádzať zámerne, napríklad po útoku na počítačovú sieť. Zmeny v distribúcií dát môžu opäť podobne nastať po útoku na sieť. Pre vysporiadanie sa s podobnými javmi je často do prúdu dát zámerne pridávaný šum, čo je do istej miery v rozpore s problémom predspracovania dát.
	\item \textit{Predspracovanie dát} je dôležitou súčasťou každej reálnej aplikácie, najmä tých pre analýzu dát. Zatiaľ čo pri tradičnej analýze dát je predspracovanie vykonané, zvyčajne doménovým expertom, ktorý rozumie dátam. Pri prúde dát toto nie je prijateľné, pretože dáta nepretržite prichádzajú. Okrem niekoľkých štúdií \citep{zliobaite2014adaptive, anagnostopoulos2008deciding} tejto problematike nebola venovaná toľká pozornosť ako pri tradičnom spracovaní a analýze dát. Hlavné výzvy, ktorým treba čeliť pri predspracovaní prúdu dát sú: \textit{šum v dátach}, \textit{hodnoty mimo väčšiny (angl. outliers)} a \textit{adaptívny výber vzorky}.
	\item \textit{Načasovanie a dostupnosť informácie} je dôležité pre väčšinu algoritmov, ktoré predpokladajú, že prijatá informácia je kompletná, ihneď dostupná, prijatá pasívne a zadarmo. Viaceré výzvy spojené s načasovaním a dostupnosťou informácie nie sú formulované a nepreskúmané: \textit{spracovanie nekompletných dát}, \textit{vysporiadanie sa so skreslenou (angl. skewed) distribúciou dát} a \textit{spracovanie oneskorených dát}.
	\item \textit{Dolovanie entít a udalostí}, kde entity sú vytvorené z viacerých inštancií prúdu dát a vytvárajú tak štruktúrované informácie (napr. agregácie). Tieto entity môžu byť niekedy spojené s výskytom udalostí. Príkladom takejto entity, či udalosti môže byť zhluk správ o zemestrasení na sociálnej sieti Twitter. 
	\item \textit{Evaluácia algoritmov pre prúdy dát} predstavuje úplne novú výzvu v porovnaní s tradičnými metódami. Pri evaluácií v prúde dát sa musíme vysporiadať s problémami ako napr.: \textit{zmeny (angl. concept drift)}, \textit{limitovaný čas pre spracovanie vzorky}, \textit{vyvíjajúce sa skreslenie tried dát}, či \textit{oneskorenie overenia}. Tejto problematike sa v poslednej dobe venuje vyššia pozornosť, ako napríklad pre evaluáciu klasifikátorov nad prúdmi dát \citep{bifet2015efficient}.
\end{itemize}

% Model prudu dat
\paragraph{Model prúdu dát} môže byť jeden z nasledujúcich: \textit{model časových radov}, \textit{pokladničný} model a model \textit{turniketu}. Podľa modelu prúdu dát existujú príslušné algoritmy, ktoré boli vytvorené pre daný model \citep{tran2014change}. Majme prúd dát $a_1, a_2, ...$, ktorý prichádza sekvenčne za sebou a popisuje sledovaný signál $A$. 
V modeli časových radov každá vzorka $a_i$ sa rovná $A[i]$, pričom vzorky prichádzajú vo vzostupnom poradí. Tento model je vhodný pre prúdy dát, ktoré nesú v sebe časovú postupnosť alebo je ich poradie určované časovou pečiatkou \citep{muthukrishnan2005data}.
Pri pokladničnom modeli môžme považovať množinu $U = {1, 2, ..., n}$ za element z prúdu dát, kde $n$ je počet vzoriek z prúdu. Sekvencia $2, 1, 2, 5$ môže byť považovaná za príklad pokladničného modelu. Tento model je často používaný v praxi, napríklad v prípadoch kde následnosť IP adries pristupuje na Web server \citep{ikonomovska2013algorithmic, muthukrishnan2005data}.
Model turniketu je veľmi podobný pokladničnému modelu. Rozdiel je v tom, že vzorka môže predstavovať aj zápornú hodnotu. Ide o analógiu z reálneho sveta kedy niektorí ľudia vchádzajú a ďalší zároveň vychádzajú turniketom, vtedy sa počet ľudí mení (napr. na zjazdovke) \citep{ikonomovska2013algorithmic, muthukrishnan2005data}. Špeciálny striktný prípad turniketu, ak celková hodnota modelu je $A \geq 0$.

% Predspracovanie prudu dat
\paragraph{Predspracovanie prúdu} je neodmysliteľným krokom v aplikáciach reálneho sveta a často časovo najnáročnejšou úlohou pre každého analytika. Nakoľko dáta prichádzajú z nehomogénneho sveta, môžu byť zašumené, nekompletné, duplicitné alebo často obsahujú hodnoty značne líšiace sa od ostatných. Predspracovanie prúdu údajov je potrebné čo najviac automatizovať. Existuje niekoľko známych metód a techník, ktoré sú používané pri predspracovaní a tiež pri redukcii dimenzionality prúdov dát \citep{krempl2014open, nguyen2015survey}:
\begin{itemize}
	\item \textit{Vzorkovanie}, napríklad použitím symbolickej reprezentácie časových radov v prúde dát. Takáto reprezentácia nám umožňuje redukciu veľkosti prenášaných dát. Daná technika pozostáva z dvoch hlavných krokov, aproximácia po častiach a následná transformácia výsledku do diskrétnych veličín \citep{sevcech2015symbolic}. 
	\item \textit{Zahadzovanie potenciálne nepotrebných vzoriek} sa uplatňuje vtedy, keď je spracujúci proces príliš zaťažený. Tu môže nastať problém, ak práve zahodená vzorka bola niečím dôležitá (napr. zmena v dátach).
	\item \textit{Agregácia údajov} môže značne znížiť objem dát, ale môže spôsobiť problém pri potrebe náhľadu do minulosti na pôvodné dáta, z ktorých vznikla. Jednou z metód, ktorá sa používa na výpočet dopytovaných agregácií nad prúdom dát je vytváranie malých sumárov z $n$ vzoriek prúdu. Tieto náhodne veľké sumáre sú použité pre výpočet agregácie \cite{dobra2002processing}.
	\item \textit{Aproximačné algoritmy} a ich použitie má za následok podstatné zrýchlenie spracovania a analýzy prúdov za predpokladu istej chybovosti. Chybovosť je zväčsa ohraničená.
	\item \textit{Posuvné okno} je prístup, ktorý vznikol s potrebou analýzy definovaného časového intervalu z prúdiacich údajov. Výstup je teda závislý na zvolenej veľkosti okna. Problém pri tomto prístupe je práve správne nastavenie veľkosti okna tak, aby sme vedeli zohľadniť zmeny v prúde dát.
\end{itemize}

\paragraph{Ohraničenia} algoritmov pre dolovanie z prúdov dát (angl. data stream mining) musia spĺňať nasledujúce podmienky \citep{babcock2002models, nguyen2015survey, wadewale2015survey}:
\begin{itemize}
	\item \textit{Jeden priechod cez dáta} (angl. single-pass) v dôsledku kontinuálneho spracovania vzoriek z nekonečného prúdu dát v čase ich vzniku, čo je v kontraste s tradičnými metódami, ktoré si udržiavajú všetky dáta v pamäti alebo na disku.
	\item \textit{Odpoveď v reálnom čase}  (angl. anytime real-time response) v zmysle, že vytvorený model je pripravený kedykoľvek predikovať triedy nových vzoriek.
	\item K dispozícii máme len \textit{ohraničenú pamäť}. Toto obmedzenie súvisí s povahou prúdov dát a to, že prúdy predstavujú potenciálne nekonečné zdroje dát.
	\item \textit{Detekcia zmien} (angl. concept-drift detection) je nevyhnutná v situácii, keď sa v dátach objavia nové vzory meniace sa v čase.
\end{itemize}

% Dolovanie a extrakcia informacii
\paragraph{Spracovanie, dolovanie a analýza dát} zo statických kolekcií dát bola študovaná niekoľko dekád. Zvýšenú pozornosť začala odborná verejnosť venovať pri aplikovaní týchto úloh na prúdy dát. Niektorým z týchto úloh sa venujeme podrobne v nasledujúcich podkapitolách:
\begin{itemize}
	\item \textit{Zhlukovanie} je úloha učenia bez učiteľa. Existuje niekoľko výskumov, ktoré sa venovali špeciálne klastrovaniu implementovaním napríklad k-mediánu a inkrementálnych algoritmov.
	\item \textit{Klasifikácia} predstavuje úlohu učenia s učiteľom, znamená to, že na vstupe očakávame označkovaný prúd dát. Táto úloha je dlho skúmaná s použitím mnohých metód, napríklad neurónových sietí, či rozhodovacích stromov.
	\item \textit{Hľadanie frekventovaných vzorov} za pomoci posuvných okien a inkrementálnych algoritmov sa využíva na detekciu vzorov v prúde. Príkladom tejto úlohy može byť napríklad hľadanie trendov v prúde dát alebo analýza nákupného košíka v doméne internetového obchodu.
\end{itemize}

% Evaluacia
\paragraph{Evaluácia} a vyhodnotenie modelov vytvorených nad prúdmi dát je základná a dôležitá úloha pre meranie kvality modelu, čo sebou prináša výzvy, pretože prúdy dát sú potenciálne nekonečné. Evaluáciu modelov je potrebné vykonávať online, pretože dáta môžu byť napríklad nerovnomerne rozdelené v prúde dát, čo predstavuje problém. Potom, tradičné techniky evaluácie známe z dávkových algoritmov pre analýzu dát nie sú použiteľné pre evaluáciu prúdov dát. \citet{bifet2015efficient} hovoria o troch hlavných mylných prístupoch k evaluácii prúdu dát:
\begin{itemize}
	\item \textit{McNemarov test} a jeho použitie na štatistické rozlíšenie kvality dvoch klasifikátorov. Aj napriek štatisticky signifikantnému rozdielu medzi klasifikátormi tento test nie je vhodný pre prúdy dát, pretože aj keď je model vytvorený rovnakým algoritmom, väčšina algoritmov je inicializovaná alebo používa nejakú náhodnú zložku. To môže viesť k zavádzajúcim výsledkom pri použití tohto testu.
	\item \textit{Rozdeľovanie množiny dát} do trénovacej a testovacej množiny vedie k nemožnosti rozoznať rýchlosť učenia rôznych klasifikátorov. Je to z dôvodu, že v dátach sa môžu objavovať napríklad zmeny, ktoré budu skreslené rozdeľovaním alebo vzorkovaním dát.
	\item \textit{Väčšina tried v posuvnom okne} môže spôsobiť pozitívne \textit{k štatistiky} a tiež pozitívne výsledky harmonického priemeru pre niektoré periódy prúdu dát.
\end{itemize}

\citet{bifet2015efficient} odporúčajú použitie nasledujúcej metódy pre evaluáciu v kontexte prúdov dát: \textit{Najprv testuj-potom-trénuj} (angl. Test-Then-Train alebo tiež Prequential) spočíva v myšlienke, že každá vzorka z prúdu dát je použitá najprv na testovanie a potom na trénovanie modelu. Keďže modely vytvorené nad prúdmi dát by mali byť schopné poskytnúť predikcie okamžite a v reálnom čase, tento prístup by nemal výrazne ovplyvniť výkon metódy. Obmenou tohto prístupu môže byť evaluácia na nejakom posuvnom okne.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%         Dopytovanie sa v prúdoch dát          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dopyty nad prúdom dát}
Vyhodnocovaniu dopytov nad statickou kolekciou dát bola v minulosti venovaná značná pozornosť, ak však hovoríme o prúdoch dát dopyty musia byt vyhodnocované kontinuálne \citep{babu2001continuous, babcock2002models}. Vzniká teda nová paradigma pre interakciu s dynamicky sa meniacimi dátami, ktorú nazývame kontinuálne dopyty (angl. continious queries) \citep{babu2001continuous}. Výsledky kontinuálnych dopytov sú produkované dynamicky v čase vzniku nových dát. Príkladom použitia takýchto dopytov je napríklad sledovanie vývoja akcií burzy. Problém môže nastať pri jednorázových dopytoch obsahujúce agregačné funkcie. Pri tradičnom spracovaní dát uložených ako statická kolekcia je dopyt vykonaný nad celou kolekciou. V prípade kontinuálneho dopytu je problém získať predchádzajúce dáta za predpokladu, že dáta niesú ukladané. Potom môžu nastať dve situácie:
\begin{enumerate}
	\item agregačná funkcia je prepočítaná zo sumárov získavaných priebežne z prúdu dát.
	\item agregačná funkcia je počítaná od momentu zadania dopytu.
\end{enumerate}
Kontinuálne dopytovanie do prúdu dát nesie so sebou nieľko výziev \citep{babcock2002models}:
\begin{itemize}
	\item \textit{Limitované pamäťové prostriedky} na algoritmy spracujúce dopyty, pretože prúd dát predstavuje potenciálne nekonečný prúd udalostí.
	\item \textit{Približné odpovede na dopyty} sú niekedy postačujúce za predpokladu, že odpoveď je dostatočne rýchla a používateľ je oboznámený v akej presnosti mu bola odpoveď poskytnutá. Techniky pre redukciu dimenzionality a objemu dát zahŕňajú napríklad: histogramy, náhodné vzorkovanie, symbolické vzorkovanie a pod.
	\item \textit{Dopytovací jazyk} by mal byť podobný jazyku SQL. Jazyk SQL je známy široko používaný deklaratívny jazyk so zavedeným štandardom, ktorý poskytuje flexibilitu a optimálne vykonanie dopytu.
\end{itemize}
Výskumné práce sa tiež venovali adaptívnym kontinuálnym dopytom nad prúdmi dát. Bolo ukázané, že takýto prístup môže mať značný prínos v oblasti výkonnosti systému vďaka jeho schopnosti adaptácie na zmeny v prúde dát. Tieto vlastnosti sú dosiahnuté aplikovaním zoskupovania indexov filtrov na priebežný výber predikátov \citep{madden2002continuously}. 
\par
Ďalší priestor na zlepšenie výkonnosti kontinuálnych dopytov nad prúdmi dát predstavujú adaptívne filtre. Pri dopytovaní sa takmer vždy vykonáva filtrovanie dát v nejakej podobe. Tento krok filtrovania je obvykle implementovaný v systéme na spracovanie dopytov. Pre zvýšenie výkonnosti dopytov je preto možné tieto filtre presunúť priamo do zdrojov dát. Ukázalo sa, že takýto prístup môže mať pozitívny dopad na výkonnosť \citep{olston2003adaptive}. Tento prístup prinesie najmä redukciu prenášaných dát výmenou za ich neúplnosť alebo nepresnosť. Výzvou tejto techniky je, že je aplikovateľná len v kontrolovanom prostredí, do ktorého všetkých súčastí vieme zasahovať. Príkladom môže byť organizácia CERN\footnote{Európska organizácia pre jadrový výskum}, ktorej jeden z hlavných experimentov ATLAS produkuje Petabajty dát počas jedného experimentu. Takéto množstvo dát by nebolo možné ukladať a následne analyzovať, preto sú aplikované filtre v každom zdroji dát (napr. rôzne fyzikálne senzory).



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%               Detekcia zmien                  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Detekcia zmien}
Detekcia zmien (angl. concept drift) zohráva v dnešnom rýchlo sa meniacom svete dôležitú úlohu. Zmeny nastávajú veľmi rýchlo a nečakane. Preto stúpa potreba detekcie zmeny a následná správna reakcia, ktorá vyplynie z detekovanej zmeny. Na to, aby sme boli schopní na tieto zmeny adekvátne reagovať, je potrebné dáta spracovávať tak, ako vznikajú a pozerať sa na ne ako na prúd udalostí. Tradičné metódy pre paralelné spracovanie uvažujú len statickú kolekciu dát \citep{tran2014change}. Existuje niekoľko typov zmien, ktoré môžu nastať v prúde dát \citep{wadewale2015survey}: \textit{náhla} (angl. sudden), \textit{inkrementálna}, \textit{graduálna}, \textit{opakujúca}, \textit{impulzívna} a \textit{šum}. Spomenuté zmeny sú zobrazené na obrázku \ref{fig:types-of-concept}.
\myFigure{images/types-of-drift}{Typy zmien (angl. concept drift) \citep{wadewale2015survey}.}{test-dia}{0.5}{h!}\label{fig:types-of-concept}
Detekcia zmeny predstavuje proces identifikácie zmeny aktuálneho stavu modelu voči predchádzajúcemu. Na tento model sa pozeráme v rôznom čase. Dôležitý rozdiel medzi zmenou a rozdielom je, že zmena hovorí o prechode modelu do iného stavu, zatiaľ čo rozdiel znamená nepodobnosť v atribútoch dvoch modelov. V kontexte prúdu je detekcia zmien proces segmentácie do rôznych segmentov a identifikácia miest s meniacou sa dynamikou\citep{ross2009online}. Metóda pre detekciu zmien musí riešiť nasledujúce úlohy \citep{tran2014change}: 
\begin{itemize}
	\item \textit{detekcia zmeny} znamená správnu identifikáciu zmeny,
	\item \textit{lokalizácia zmeny} hovorí o identifikovaní momentu kedy, zmena nastala.
\end{itemize}
 Týmto úlohám je potrebné venovať dostatočnú pozornosť, pretože zmeny môžu byť falošné alebo dočasné, čo so sebou prináša problém lokalizácie danej zmeny. Ďalší termín, ktorý je potrebné zadefinovať je detekovaná zmena (angl. concept drift). Detekcia concept drift-u sa sústreďuje na označkované dáta, zatiaľ čo detekcia zmeny pracuje aj s neoznačkovanými dátami. Označkované dáta pre detekciu concept drift-u sú dôležité, pretože nás zaujíma skutočný význam a hodnota pozorovaní. Naopak, pri detekcii zmien niekedy môže byť postačujúce sledovať zmenu v distribúcií dát alebo početnosti. V praxi sa ale ukázalo, že aj detektory, ktoré sú do istej miery založené na sledovaní zmeny distribúcie dát dokážu úspešne detekovať concept-drift.
 \par
Metódy pre detekovanie zmien môžme klasifikovať do nasledujúcich prístupov \citep{liu2010mining}: \textit{metódy založené na stave}, \textit{metódy sledujúce trend} a \textit{prahové metódy}. Algoritmus pre detekciu zmien by mal spĺňať aspoň nasledovné požiadavky: \textit{presnosť}, \textit{rýchlosť} a \textit{odpoveď v reálnom čase}. Algoritmus by tiež mal detekovať čo najmenej chybných zmien a čo najviac správnych presných miest zmeny. Algoritmy by mali byť prispôsobené reálnemu prostrediu a spracovaniu prúdov vysokých objemov a rýchlostí. Na obrázku \ref{fig:zmeny-vseobecny-dia} je zobrazený všeobecný diagram pre detekciu zmeny v prúde udalostí.

\myFigure{images/2_zmeny_vseobecny-diagram}{Všeobecný diagram zobrazujúci detekciu zmeny v prúde udalostí \citep{tran2014change}. Komponent slúžiaci na dolovanie v prúde dát implementuje detektory zmien. Podľa výstupov týchto detektorov sa výsledný model adaptuje a zohľadňuje zmeny na vstupe.}{test-dia}{0.5}{h!}\label{fig:zmeny-vseobecny-dia}

% Techniky a metody pre detekciu zmeny v prudoch
Pre detekciu zmeny v prúdoch dát bolo vyvinutých niekoľko techník a metód. Niektoré z nich nižšie podrobnejšie popisujeme.

% Charakteristika dat
 Jeden z druhov metódy pre detekciu zmien zohľadňuje \textit{charakteristiku dát}. Najčastejšie môžme prúdy klasifikovať do kategorických (n-tice, množiny) alebo numerických prúdov. Ak hovoríme o kategorických prúdoch, dáta obsiahnuté v prúde majú kategorický charakter, príkladom sú rôzni výrobcovia áut: $x \in \{Volvo, Toyota\}$. Pri numerických prúdoch dáta predstavujú numerické hodnoty $x \in {\rm I\!R}$. Pre každý takýto prúd boli vyvinuté príslušné algoritmy. Problém nastáva pri aplikáciach s dátami reálneho sveta, kedy prúdy často obsahujú numerické aj kategorické dáta. V takýchto situáciach má zmysel dáta rozdeliť do rovnomenných skupín obsahujúce dáta rovnakého typu. Na tieto skupiny sú následne použité príslušné algoritmy. Prúdy dát sa ďalej môžu klasifikovať do označkovaných a neoznačkovaných prúdov. Neoznačkované prúdy obsahujú dáta nezaradené do žiadnej triedy. Naopak označkované prúdy nesú v sebe informáciu o tom, do ktorej triedy patrí vybraný element. Príkladom opísaného prúdu môže byť prúd nákupov internetového obchodu. Rôzny charakter prúdu predstavuje rôzne zmeny a prístup na ich riešenie pri detekcii zmien v prúde \citep{tran2014change}.

% Kompletnost statistickej informacie
\textit{Metóda pre detekciu zmeny} sa označuje skratkou DDM z anglického Drift Detection Method. Je to metóda zaoberajúca sa detekciou zmeny modelu. Majme prúd dát $(x_i,y_i)$ kde $x_i$ predstavuje atribúty a $y_i$ skutočnú triedu vzorky. Model sa potom snaží predikovať skutočnú triedu $y_{i+1}$ novej vzorky. Gama a spol. založili DDM na fakte, že každá iterácia klasifikátora predikuje triedu vzorky. Klasifikátor je binárny, takže trieda môže byť len $pravda$ alebo $nepravda$. Potom pre množinu vzoriek chyba predstavuje náhodnú premennú z Bernoulliho pokusov (angl. Bernoulli trials). Vďaka tomu môžme chybu modelovať s bínomickým rozdelením. Nech $p$ je pravdepodobnosť zlej predikcie a $s_i$ je štandardná odchýlka vypočítaná nasledovne:
\begin{align*}
s_i = \sqrt{ \frac{p_i(1-p_i)} {i} }
\end{align*}
Pre každú vzorku z prúdu sú udržiavané dve premenné, $p_{min}$ a $s_{min}$. Ich hodnoty sú použité na výpočet varovnej hodnoty, ktorá slúži na definovanie optimálnej veľkosti kontextového okna. Kontextové okno si udržiava staré vzorky obsahujúce nový kontext, resp. zmenu, či posun pojmu a minimálny počet elementov zo starého kontextu. Ak sa následne zníži množstvo chybne predikovaných vzoriek, okno je zahodené ako zle identifikovaná zmena (false alarm). Naopak, ak je dosiahnutá dostatočná varovná úroveň, predtým naučený model je zahodený a je vytvorený nový, ale iba zo vzoriek uložených do kontextového okna \citep{gama2004learning, brzezinski2010mining}.
\par
Existuje tiež rozšírenie EDDM, ktoré je modifikáciou DDM. Tento algoritmus používa rovnakú techniku varovných alarmov, ale namiesto klasifikácie chyby používa metriku množstva rozdielnych chýb. EDDM metóda dosahuje lepšie výsledky pri postupných zmenách, ale je citlivejšia na šum v dátach \citep{wadewale2015survey}.

% ADWIN
\textit{ADWIN} je skratka pre algoritmus s názvom adaptívne posuvné okno (angl. adaptive windowing). Tento algoritmus je vhodný je hlavne pre prúdy s náhlymi zmenami, pričom si udržiava okno $W$ s najnovšími vzorkami. Okno $W$ je automaticky zväčšované ak nieje detekovaná žiadna výrazná zmena v prúde a naopak, zmenšované ak bola zmena detekovaná. Obmedzenie nárastu okna donekonečna (žiadna zmena v prúde) je možné parametrom algoritmu, ktorý bude limitovať dĺžku okna $W$. ADWIN taktiež poskytuje ohraničenie výkonu na základe množstva falošne pozitívne a falošne negatívnych vzoriek \citep{wadewale2015survey}. Základná verzia algoritmu ADWIN je vhodná pre jednodimenzionálne dáta. Ak je potrebné detekovať zmeny pre viacdimenzionálne dáta, potom sa vytvára paralelne niekoľko okien pre každú dimenziu dát \citep{brzezinski2010mining}.
\par
Existuje mnoho ďalších prístupov ako sa vysporiadať so zmenami v prúde, napríklad: exponenciálne váhovaný posuvný priemer, štatistické testovanie rovnomerného podielu alebo súborové (angl. ensemble) metódy. Popis všetkých metód je nad rámec tejto práce.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%             Detekcia anomálií                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Detekcia anomálií}
Detekcia anomálií (angl. anomaly detection) predstavuje proces identifikácie dát, ktoré sa význačne vychyľujú (angl. deviate) od historických vzorov \citep{hodge2004survey}. Anomálie môžu spôsobovať chyby v meraní senzorov, pri prenose dát, nezvyčajné správanie systému, či zámerné vytváranie anomálií v používateľmi generovanom obsahu. 
Takže detekcia anomálií má veľa praktického použitia napríklad v aplikáciach dohliadajúcih na kvalitu a kontrolu dát \citep{hill2007real} alebo na adaptívne monitorovanie sietí \citep{hill2010anomaly}. Tieto aplikácie často kladú požiadavku, aby boli anomálie detekované v čase ich vzniku, teda v reálnom čase. Potom metódy pre detekciu anomálií musia byť rýchlo a efektívne spracovať dáta a zároveň mať inkrementálny charakter.
\par
V minulosti sa obvykle anomálie detekovali manuálne s pomocou vizualizačných nástrojov, ktoré doménovým expertom pomáhali v tejto úlohe. Manuálne metódy avšak zlyhávajú pri detekcii anomálií v reálnom čase. Výskumníci navrhli niekoľko metód s myšlienkou strojového učenia sa a automatizovaného štatistického vyhodnocovania, ku ktorým patrí napríklad \textit{minimálny objem elipsoidu}, \textit{konvexný zvon}, \textit{najbližší sused}, \textit{zhlukovanie}, \textit{klasifikácia neurónovou sieťou}, \textit{klasifikácia metódou podporných vektorov} a \textit{rozhodovacie stromy} \citep{hill2010anomaly}. Tieto metódy sú pochopiteľne rýchlejšie v porovnaní s manuálnou detekciou. Ich význačným nedostatkom je, že bez úpravy nie sú vhodné pre prúdové spracovanie v reálnom čase. Existujú napríklad rozhodovacie stromy, ktoré si dokážu budovať model inkrementálne, ale líšia sa od dobre známych algoritmov. Tejto metóde sa v práci podrobne venujeme v inej kapitole.

\textit{Dátovo riadená metóda} (angl. data-driven) využíva dátovo riadený jednorozmerný autoregresívny model prúdu dát a predikčný interval (ďalej len PI) vypočítaný z posledných historických dát na identifikáciu anomálií v prúde \citep{hill2010anomaly}. Dátovo riadený model časového radu sa využíva preto, že je jednoduchší na implementáciu a použitie v porovnaní s ostatnými modelmi prúdov dát. Tento model tiež poskytuje rýchle a presné prognózy. Dáta sú potom klasifikované ako anomálie na základe toho, či sú spadnú do zvoleného intervalu PI. Metóda teda poskytuje principiálny rámec pre výber hraničného prahu, kedy majú byť anomálie klasifikované. Výhoda metódy je, že nevyžaduje žiadne vopred označkované vzorky dát. Je veľmi dobre škálovateľná na veľké objemy dát a vykonáva inkrementálne počítanie tak, ako dáta vznikajú.
Metóda pozostáva z nasledujúcich krokov so začiatkom v čase \textit{t}:
\begin{enumerate}
	\item Použitie modelu na predikciu o krok vpred (angl. one-step-ahead), ktorý má ako vstup $\displaystyle D^t = \{x_{t-q+1}, ..., x_t\}$, \textit{q} je rôzne meranie \textit{x} v čase \textit{t} a $\displaystyle D^t$ je model predikcie. Tento model je použitý ne predikovanie hodnoty $\displaystyle \overline{x}_{t+1}$ ako očakávaná hodnota v čase \textit{t+1}.
	\item Výpočet hornej a spodnej hranice kam by malo spadnúť pozorované meranie s pravdepodobnosťou \textit{p}.
	\item Porovnanie pozorovania v čase \textit{t+1}, či spadá do určeného intervalu. Ak spadne mimo intervalu, objekt je klasifikovaný ako anomália.
	\item 
		\begin{enumerate}
			\item Pri stratégii metódy detekcie anomálií a zmiernenia ADAM (angl. anomaly detection and mitigation), ak je pozorovaný objekt klasifikovaný ako anomália, je potrebné modifikovať $\displaystyle D^t$ odstránením $\displaystyle x_{t-q+1}$ z konca pozorovaného okna a pridaním $\displaystyle \overline{x}_{t+1}$ na začiatok okna, čím vytvoríme $\displaystyle D^{t+1}$.
			\item Pri jednoduchej stratégii detekcie anomálií AD (angl. anomaly detection), je potrebné modifikovať $\displaystyle D^t$  odstránením $\displaystyle x_{t-q+1}$ z konca okna a pridaj $\displaystyle x_{t+1}$ na začiatok okna čím vznikne $\displaystyle D^{t+1}$.
		\end{enumerate}
	\item Je potrebné opakovať kroky \textit{1-4}
\end{enumerate}
\paragraph{Metóda dynamických bayesových sietí} (angl. Dynamic Bayesian Networks) bola vytvorená pre detekciu anomálií v prúdoch zo senzorov umiestnených v životnom prostredí \citep{hill2007real}. Bayesové siete predstavujú acyklický orientovaný graf zobrazený na obrázku \ref{fig:anomalie-dbn}, v ktorom každý uzol obsahuje pravdepodobnostnú informáciu v súvislosti k všetkým možným stavom premennej. Táto informácia spolu s topológiou bayesovej siete špecifikuje úplné spojenie distribúcie stavu premennej, pričom sada známych premmených môže byť použitá na odvodenie hodnoty neznámych premenných. Dynamické bayesové siete s topológiou vyvíjajúcou sa v čase, pridávajú nové stavové premenné pre lepšiu reprezentáciu stavu systému v aktuálnom čase \textit{t}. Stavové premenné môžeme kategorizovať ako \textit{neznáme} predstavujúce skutočný stav systému a \textit{merané}, ktoré sú nedokonalé merania. Tieto premenné môžu byť naviac diskrétne alebo spojité. Nakoľko sa veľkosť siete zväčšuje s časom, vytváranie záverov použitím celej siete by bolo neefektívne a časovo náročné. Preto boli vyvinuté aproximačné algoritmy ako \textit{Kalmanové filtrovanie} alebo \textit{Rao-Blackwellized časticové filtrovanie}. Boli navrhnuté dve stratégie pre detekovanie anomálií v prúde dát \citep{hill2007real}:
\begin{itemize}
	\item \textit{Bayesov dôveryhodný interval} (angl. Bayesian credible interval - BCI), ktorý sleduje viacrozmernú Gaussovu distribúciu lineárneho stavu premennej korešpondujúcu s neznámym stavom systému a jej meraným náprotivkom.
	\item \textit{Maximálne posteriori meraný status} (angl. Maximum a posteriori measurement status - MAP-ms) používa komplexnejšiu dynamickú bayseovú sieť. Princíp je rovnaký ako pri BCI, pričom MAP-ms metóda je naviac rozšírená o status (napr. anomália áno/nie), ktorý je reprezentovaný distribúciou diskrétnej premennej každého merania senzoru.
\end{itemize}
\myFigure{images/2_anomalie_DBN}{Štruktúra dynamickej bayseovej siete. Vektor $X$ reprezentuje spojitú zložku, neznáme alebo tiež nazývané skryté premenné systému a vektory $M$ predstavujú spojité pozorované premenné v čase $t$ \citep{hill2007real}.}{anomalie-dbn}{0.65}{h!}\label{fig:anomalie-dbn}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                     FP                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{FP} -- otazne


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                Zhlukovanie                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Zhlukovanie}
Zhlukovanie (angl. clustering) je proces zoskupovania objektov z dátovej množiny do zhlukov (angl. cluster) na základe čŕt objektov. Cieľom je vytvoriť zhluky, vrámci ktorých budú objekty čo najviac podobné a objekty medzi zhlukmi čo najviac odlišné. Podobne ako pri tradičných metódach pre zhlukovanie, aj metódy pre prúdy dát môžu byť rozdelené do piatich kategórií \citep{nguyen2015survey, aggarwal2014survey}: rozdeľovacie (angl. partitioning) metódy, hierarchické (angl. hierarchical) metódy, metódy založené na hustote (angl. density-based), metódy založené na mriežke (angl. grid-based) a metódy založené na modeli (angl. model-based). Algoritmus potrebuje naviac kvantifikovať mieru podobnosti, či vzdialenosti zhlukov. Existujú štyri najpoužívanejšie spôsoby pre meranie vzdialenosti: minimálna vzdialenosť (angl. single-linkage), maximálna vzdialenosť (angl. complete-linkage), priemerná a stredná vzdialenosť. Spomenuté miery vzdialenosti sa v niektorej literatúre uvádzajú ako typy zhlukovania, pričom metrika vzdialenosti môže byť napríklad kosínusová podobnosť alebo euklidová vzdialenosť. V inej literatúre je naopak abstrahované od týchto metrík a miery ako minimálna vzdialenosť sú považované za miery podobnosti zhlukov. Zhlukovanie je príklad \textit{učenia bez učiteľa} (angl. unsupervised learning) narozdiel od klasifikácie. Metódy zhlukovania sú často používane počas predspracovania dát napríklad s cieľom redukcie dimenzionality.

\textit{Rozdeľovacie metódy} (angl. partitioning methods) rozdeľujú dátovú množinu o $n$ objektoch do $k$ partícií, kde každá partícia predstavuje zhluk, pričom platí $k\leq n$. Parameter $k$ je obvykle definovaný používateľom vopred. Najznámejšie tradičné metódy sú $k-means$ a $k-medians$. Existujú implementácie upravujúce $k-means$ tak, aby bola použiteľná na prúdy dát. Všetky tieto implementácie spracujú prúd v malých dávkach, takže nie celkom spôsobom ako je vhodné spracovať prúdy dát \citep{gaber2005mining}.
\par
Jeden z prvých algoritmov, ktoré boli navrhnuté pre prúdy dát je algoritmus $STREAM$, je rozšírením algoritmu $k-medians$. Algoritmus používa techniku rozdeľuj a panuj (angl. divide-and-conquer) s cieľom vytvárania zhlukov inkrementálne. Účelová funkcia algoritmu $STREAM$ je nasledovná:
\begin{align*}
SSQ(M,C) = \sum_{i=1}^{k} \sum_{x_j\Leftarrow c_i} dist(x_j, c_i)
\end{align*}
kde $x$ je dátová vzorka a $c$ reprezentuje zhluk (medián). Funkcia $dist$ je funkcia na meranie vzdialenosti medzi zhlukmi. Algoritmus avšak tiež spracováva dáta v malých dávkach. Na rozhodnutie o veľkosti dávky používa algoritmus $LOCALSEARCH$.
% TODO: pridat tabulky s pouzitim algoritmov -- veduci to chcel
\textit{Metódy založené na hustote} vytvárajú profil hustoty dátovej množiny. Tento profil je následne použitý na zhlukovanie. Znamená to teda, že za zhluky považujeme miesta v priestore s vysokou hustotou objektov. Výhodou tejto metódy je, že dokáže objaviť v dátach aj neobvyklé tvary zhlukov. Najznámejšie implementácie sú $DBSCAN$ a $OPTICS$. Toto je všeobecná výhoda metód založených na hustote v porovnaní s rozdeľovacími metódami \citep{han2011data}.
\par
Algoritmus $DenStream$ je rozšírením algoritmu $DBSCAN$, ktorý je vhodný pre zhlukovanie prúdov dát. Tento algoritmus podobne ako $CluStream$ algoritmus navrhnutý Aggarwalom \citep{aggarwal2003framework} vytvára mikrozhluky na zachytenie informácie o prúde dát. Mikrozhluky sú kontinuálne aktualizované a udržiavané v kolekcii mikrozhlukov. Algoritmus používa oslabujúci model na zníženie váh elementov v čase. Vytvárané sú tri typy mikrozhlukov: základný, potenciálny a vyčnievajúci (angl. outlier). Algoritmus potom aplikuje známy $DBSCAN$ algoritmus na vytvorené mikrozhluky, pričom zhluk vzniká z viacerých mikrozhlukov, ktoré su pokope \citep{nguyen2015survey}.
\par
Algoritmus $OPTICS-stream$ je opäť rozšírenie algoritmu $OPTICS$ \citep{ankerst1999optics}. Podobne ako $DenStream$ vytvára mikrozhluky a aplikuje oslabujúci model. Na vytvorenie finálnych zhlukov rovnako používa pôvodný algoritmus $OPTICS$ z vytvorených mikrozhlukov.

\textit{Metódy založené na modeloch} sa snažia optimalizovať podobnosť medzi dátami a statickými modelmi. Známe tradičné metódy sú napríklad \textit{Expectation-Maximization (EM)} a \textit{Self-Organizing Map (SOM)}. EM je jemná (angl. soft) metóda pre zhlukovanie, SOM je metóda neurónových sietí.
\par
\textit{SWEM} je algoritmus rozšírený z EM algoritmu. Tento algoritmus používa posuvné okno. Každý mikrokomponent je reprezentovaný n-ticou (váha, priemer, kovariančná matica). Najprv je aplikovaný algoritmus EM na získanie konvergujúcich parametrov, následne používa získané parametre ako inicializačné hodnoty pre vytvorenie modelu. SWEM tiež aplikuje oslabujúci model na expiráciu sumarizačných štatistík mikrokomponentov \citep{nguyen2015survey}.
\par
Ďalším algoritmom vytvárajúcim statický model je \textit{GCPSOM}, ktorý je hybridným algoritmom vytvoreným z \textit{GSOM} a \textit{CPSOM}. Algoritmus GSOM je vyvíjajúci sa SOM, kde nieje potrebné vopred definovať veľkosť mapy. Mapa GSOM dynamicky rastie podľa hodnoty akumulovaných chýb. CPSOM je bunkový pravdepodobnostný SOM používaci oslabujúce okno s cieľom redukcie váh neurónov. Teda, GCPSOM má schopnosť dynamického rastu mapy čŕt pre zhlukovanie prúdov dát a udržiavanie zhlukov tak, ako sa prúd vyvíja v čase \citep{nguyen2015survey}.

\textit{Hierarchické metódy} zoskupujú dátové objekty do zhlukov hierarchických stromov. Tieto metódy ďalej rozdeľujeme na aglomeratívne a rozdeľovacie, kde je dekompozícia hierarchií formovaná zdola nahor spájaním alebo zhora nadol rozdeľovaním. Tradičné metódy sú napríklad BIRCH, CURE alebo  ROCK. Metóda CluStream je použiteľná pre prúdy dát, pričom rozširuje tradičnú metódu BIRCH. CluStream používa mikrozhluky pre získanie súmárnych informácií o prúde dát. Mikrozhluky sú definované ako rozšírenie funkčných vektorov metódy BIRCH s pridanou časovou zložkou. CluStream si udržuje množinu mikrozhlukov. Nový mikrozhluk je spojený s iným podobným mikrozhlukom alebo odstránený ako outlier. Tento algoritmus tiež analyzuje vývoj mikrozhlukov s cieľom odhaliť zmeny v prúde dát \citep{nguyen2015survey}. Algoritmus HPStream je rozšírením algoritmu CluStream, ktorý adresuje problém zhlukovania vysoko dimenzionálných dát. Tento algoritmus sa vysporadúva s takýmito dátami projekčnou technikou pre výber najlepšieho atribútu pre zhluky. SWClustering je algoritmus, ktorý rieši problém postupnej degradácie algoritmu CluStream, ak beží dlhú dobu. SWClustering vytvára dočasný zhluk čŕt pre posuvné okno. Následne je použitý exponenciálny histogram čŕt zhlukov pre identifikáciu zmien v prúde dát. Tento algoritmus tiež dosahuje lepšiu časovú a pamäťovú efektivitu ako CluStream \citep{han2011data}.

\textit{Metódy založené na mriežke}
rozdeľujú priestor na multidimenzionálnu mriežku. Mriežka môže obsahovať veľa buniek, pričom každá môže mať svoj podpriestor, v ktorom si udržuje sumárne informácie o dátach. Zhluky sú potom identifikované hustými oblasťami v okolí buniek. Známy algoritmus pre zhlukovanie prúdov dát podľa mriežky je CellTree \citep{han2011data}. Algoritmus je inicializovaný rozdelením priestoru do množiny rovnako veľkých buniek. CellTree bol rozšírený na lepšiu verziu Cell*Tree, ktorý používa algoritmus BTree na ukladanie informácií o zhlukoch. Cell*Tree tiež aplikuje starnúci model na zvýraznenie poslednej zmeny v prúde dát.
\par
Pre každú z kategórii metód používaných pri úlohe zhlukovania existuje niekoľko algoritmov použiteľných pre prúdy dát. Väčšina spomenutých metód vznikla z obdobných metód pre dávkové spracovanie.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                Klasifikácia                   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Klasifikácia}
\label{ulohy-klasifikacia}
Klasifikácia dát je dobre známa úloha a problém dolovania, analýzy a spracovania dát. Klasifikácia prúdov dát má zmysel často pre doménových expertov, ktorí potrebujú vytvárať detailné analýzy, či predikčné a klasifikačné modely. Pod pojmom doménový expert chápeme človeka, ktorý rozumie analyzovaným dátam a pracuje s bežnými analytickými nástrojmi ako napríklad Google Analytics\footnote{https://www.google.com/analytics/
} alebo IBM SPSS\footnote{https://www-01.ibm.com/software/sk/analytics/spss/}. Použitie klasifikácie prúdov dát má zmysel v mnohých oblastiach a prípadoch použitia:
\begin{itemize}
	\item \textit{Detekcia podvodov pri finačných prevodoch}. Je dôležité detekovať falošnú, či podvodnú platbu platobnou kartou takmer v reálnom čase pre minimalizáciu nákladov vzniknutých s jej neskorím riešením. Vytvorenie klasifikátora nad prúdmi dát ma zmysel práve preto, že transakcie predstavujú prúd dát často nesúci sezónne vzory a zmeny, na ktoré sa nevedia dobre adaptovať tradičné metódy.
	\item \textit{Klasifikácia zákaznika na webe}. Toto má zmysel napríklad pre internetové obchody ako Amazon.com. Pre podobné stránky je prínosné vedieť klasifikovať, či je navštevník webu potenciálny zakazník alebo má tendenciu odísť. Podľa týchto zistení môže majiteľ stránky vytvoriť vhodnú ponuku pre zákazníka s cieľom udržať ho na stránke.
	\item \textit{Klasifikácia sieťovej prevádzky}. Cieľom je klasifikovať potenciálne pokusy o útoky na sieť, ich eliminácia a stým spojená minimalizácia prestoja (angl. downtime) siete a nákladov spôsobených škodami z úspešného útoku.
\end{itemize}
Pre všetky vyššie opísané prípady použitia má zmysel zohľadniť zmeny v prúde dát v modeli, pretože ak sa mení správanie používateľa na webe v závislosti od zmien na stránke, napríklad v podobe zmeny dizajnu, chceme tieto zmeny odzrkadliť aj vo výslednom modeli. Rovnako má zmysel tieto zmeny aj interpretovať prostredníctvom vizualizácie používateľovi.
\par
Existuje niekoľko dobre známych a používaných metód, niektoré z nich sú podrobne opísané v kapitole \ref{ulohy-klasifikacia}, pre klasifikáciu prúdov dát:
\begin{itemize}
	\item \textit{Hoeffdingove stromy} a ich rozšírenia, ktoré sú schopné adaptovať sa na zmeny (angl. concept drift) v dátach \citep{hulten2001mining, bifet2009adaptive}.
	\item \textit{Bayesová klasifikácia} a jej rozšírenia v podobe Bayesových stromov, ktoré ukázali použitie najmä pri detekcii anomálií v dátach \citep{hill2007real}.
	\item \textit{Neurónové siete a evolučné metódy}, pričom evolučné programovanie našlo uplatnenie v stochastických optimalizačných problémoch. Vlastnosti evolučných algoritmov môžu byť tiež aplikované na spracovanie prúdu dát s cieľom vysporiadať sa so zmenami v dátach. Experimentálne použitie neurónových sietí ukázalo porovnateľné výsledky s rozhodovacími stromami.
	\item \textit{Súborové metódy} (angl. ensemble), ktoré aplikujú vrecovanie (angl. bagging) a zvyšovanie (angl. boosting) s cieľom spresnenia modelu pomocou nájdenia optimálneho nastavenia a kombinácie viacerých klasifikátorov. Náhodné lesy sú typickým príkladom súborových metód, dokážú sa vysporiadať so zmenami v dátach, pričom časová náročnosť spracovania vzorky je $O(1)$ \citep{abdulsalam2011classification}.
	\item Ďalšie metódy sú napríklad: \textit{k-najbližších susedov} a \textit{metóda podporných strojov}. Niektoré z týchto metód podrobnejšie opisujeme v tejto podkapitole.
\end{itemize}

\par
Klasifikácia je proces hľadania všeobecného modelu vytvoreného na základe predchádzajúcich pozorovaní. Tieto pozorovania, resp. prúd dát, musí obsahovať označkované dáta, klasifikácia predstavuje teda úlohu učenia s učiteľom. Vytvorený model je potom použitý na klasifikovanie nových dát. Proces klasifikácie pozostáva tradične z dvoch krokov: \textit{učenie} a \textit{trénovanie}. V kontexte klasifikácie prúdu dát je avšak učenie kontinuálne. Testovanie môže byť tiež kontinuálne, avšak to závisí od zvolenej metódy pre evaluáciu klasifikátora. Počas učenia sa snažíme podľa algoritmu vytvoriť klasifikačný model z trénovacích dát (trénovacia množina). Počas testovania je vytvorený model použitý na klasifikovanie neoznačkovaných dát z testovacej množiny. Existujú viac dobre známych metód pre klasifikáciu: rozhodovacie stromy, naivný Bayes, neurónové siete alebo k-najbližších susedov \citep{nguyen2015survey}. Niektoré z týchto metód sú v upravenej podobe vhodné na klasifikáciu prúdov dát, vybrané z nich sú detailnejšie popísané v tejto podkapitole. Základné podmienky použiteľnosti algoritmov pre klasifikáciu prúdu dát sú limitované: \textit{ohraničený čas spracovania dát}, \textit{ohraničená veľkosť použitej pamäte} a \textit{okamžité použitie modelu}.
\par
Problém klasifikácie je zvyčajne formálne definovaný nasledovne: nech $A$ je trénovacia množina o $N$ prvkoch vo forme $(x,y)$, kde $y$ predstavuje skutočnú triedu vzorky a $x$ je vektor s $d$ atribútmi. Každý atribút môže nadobúdať numerické alebo kategorické hodnoty. Cieľom je vytvoriť na základe trénovacej množiny model resp. funkciu $y=f(x)$, ktorá bude predikovať triedu $y$ pre nové vzorky $x$ \citep{domingos2000mining}. Jednou z metrík, ktoré sa snažíme optimalizovať pre vybraný klasifikátor môže byť napríklad presnosť alebo druhá odmocnina priemernej chyby.
\par
Väčšina inkrementálnych metód používa vzorkovanie s cieľom zvýšiť presnoť klasifikátora \citep{aggarwal2014survey, nguyen2015survey}. Často je použitá technika zásobníkového vzorkovania (angl. Reservoir sampling) umožňujúca zvýšiť efektivitu klasifikátora. Myšlienka je v udržiavaní malej kontinuálnej trénovacej vzorky dát. Klasifikačný algoritmus je potom kedykoľvek aplikovaný na vzorku s cieľom vytvorenia modelu \citep{aggarwal2014survey}. Klasifikácia je problém \textit{učenia s učiteľom} (angl. supervised learning) čo znamená, že pri trénovaní sú známe skutočné triedy dátových vzoriek.

% Multi naive bayes
\textit{Multinomiálny naivný Bayes} je klasifikátor najčastejšie používaný na klasifikáciu dokumentov obvykle poskytujúci dobré výsledky týkajúce sa presnosti výsledku a rýchlosti spracovania. Túto metódu je jednoduché aplikovať v kontexte prúdu dát, pretože je inkrementálna \citep{bifet2010sentiment}. Multinomiálny naivný Bayes sa pozerá na každé pozorovanie ako na zhluk slov. Pre každú triedu $c$, $P(w|c)$, pravdepodobnosť, že slovo $w$ patrí do tejto triedy je odhadovaná z trénovacích dát jednoducho vypočítaním relatívnej početnosti každého slova v trénovacej sade pre danú triedu. Klasifikátor potrebuje naviac nepodmienenú pravdepodobnosť $P(c)$. Za predpokladu, že $\displaystyle n_{wd}$ je počet výskytov slova $w$ v dokumente $d$, pravdepodobnosť triedy $c$ z testovacieho dokumentu je nasledovaná: \newline
\begin{align*}
P(c|d) = \frac{P(c)\prod _{w \in d} P(w|c)^{n_{wd}}} {P(d)}
\end{align*}
Kde $P(d)$ je normalizačný faktor. Aby sme sa vyhli problému kedy sa trieda nevyskytuje v datasete ani jeden krát, je bežné použitie Laplacovej korekcie a nahradenie nulových početností jednotkou, resp. inicializovať početnosť každej triedy na 1 namiesto 0. Gaussova aproximácia môže byť tiež použitá v klasifikátore naivný Bayes za predpokladu, že distribúcia dát je podobná normálnemu (tiež Gaussovo z angl. Gaussian) rozdeleniu. Dva parametre sú potrebné uloženie normálneho rozdelenia, priemer a štandardná odchýlka. V prúde dát je potrebný jeden parameter naviac, počet pozorovaných vzoriek. Táto metóda je pamäťovo nenáročná no nevýhodou je predpoklad normálneho rozdelenia vstupných dát \citep{salperwyck2015incremental}.

% SGD a SVM
\textit{Stochastický gradientný zostup a metóda podporných strojov} (angl. Stochastic Gradient Descent, SGD). Bifet a Frank v ich práci použili implementáciu tzv. vanilla stochastický gradientný zostup s pevnou rýchlosťou učenia, optimalizujúc stratu s $L_2$ penalizáciou. $L_2$ penalizácia je často používaná pri podporných vektorových strojoch (angl. Support Vector Machines, ďalej len SVM). Lineárny stroj, ktorý je často aplikovaný na problémy klasifikácie dokumentov, optimalizujeme funkciu straty nasledovne:
\begin{align*}
\frac{\lambda }{2}\left \| w \right \|^{2}+\sum [1-(yxw + b)]_{+}
\end{align*}
kde $w$ je váhovaný vektor, $b$ je sklon, $\lambda$ regulačný parameter a označenie triedy $y$ je z intervalu $\{+1, -1\}$.
\par
SVM ukazujú dobré výsledky v mnohých úlohách a problémoch strojového učenia, ak je táto metóda použitá na statické datasety. Avšak, ich použitie v neupravenej forme je problematické na prúdy dát kvoli ich časovej zložitosti $O(N^3)$ a pamäťovej zložitosti $O(N^2)$, kde $N$ je počet dátových vzoriek \citep{nguyen2015survey}. Tsang a spol. navrhli metódu jadrových vektorových strojov (angl. Core Vector Machine, CVM), ktorá používa uzavretie minimálnou guľou (angl. Minimum Enclosing Ball - MEB,v 2D priestore tiež známe ako problém pokrytia minimálnou kružicou) na redukciu časovej a pamäťovej zložitosti. Metóda StreamsSVM je rozšírením CVM a bola navrhnutá s ohľadom na spracovanie prúdov dát \citep{rai2009streamed}. StreamsSVM používa flexibilný rádius MEB, ktorý sa mení podľa nových vzoriek z prúdu dát. Výsledky sa blížia k výsledkom z optimálneho algoritmu, avšak problém tejto metódy je neschopnosť vysporiadať sa so zmenami (angl. concept-drift) v prúde dát.


% HFDT, VFDT, CVFDT
\textit{Rozhodovacie stromy} (angl. Decision trees) sú častou metódou používanou na klasikáciu. Modely rozhodovacích stromov dosahujú v praxi vysokú presnosť zatiaľ čo model je jednoduchý na vysvetlenie \citep{jin2003efficient, hulten2001mining, domingos2000mining, aggarwal2014survey}. Existuje niekoľko škálovateľných metód pre rozhodovacie stromy, napríklad SLIQ, RainForest alebo BOAT \citep{aggarwal2014survey}. Napriek tomu, že sú tieto metódy škálovateľné, nie sú navrhnuté a ani vhodné na použitie pre prúdy dát. Neskôr boli navrhnuté rodiny algoritmov ako ID3, ktoré boli síce navrhnuté aj s ohľadom na prúdy dát, ale problém je že neboli tak aby  zohľadnili zmeny v modely. Rozhodovacie stromy predikujú resp. klasifikujú novú vzorku do triedy $y$ podľa výsledkov testov v rozhodovacích uzloch a triedy v liste stromu do ktorého spadne vzorka.
\par
Jedna z prvých metód, ktorá bola navrhnutá špecificky pre prúdy dát je \textit{Hoeffdingov strom} (angl. Hoeffding tree, ďalej len HT).  Je to najznámejšia implementácia rozhodovacích stromov v použití prúdového spracovania \citep{domingos2000mining, aggarwal2014survey, nguyen2015survey}. HT vyžaduje prečítanie každej novej vzorky z prúdu najviac jeden krát. Táto vlastnosť umožňuje použitie HT nad prúdmi dát s akceptovateľnou časovou a pamäťovou zložitosťou. Prečítané vzorky nie je potrebné ukladať na disk. HT využíva fakt, že malá vzorka dát je často postačujúca na výber optimálneho rozdelovacieho atribútu. Toto tvrdenie je matematicky podporené Hoeffdingovou mierou alebo súčtovou Chernoffovou mierou \citep{domingos2000mining, han2011data}. Rutkowski a spol. tvrdia, že stromy, ktoré používaju Hoeffdingovu mieru v skutočnosti používajú McDiarmidovu mieru a mali by sa tieto stromy nazývať McDiarmdove \citep{rutkowski2013decision}. HT dosahujú sa vo všeobecnosti asymptoticky približujú kvalitou k tým, ktoré sú vytvorené metódou pre dávkové spracovanie \citep{hall2009weka}.
\par
Predpokladajme $N$ nezávislých pozorovaní náhodnej premennej $r \in R$ kde $r$ je metrika výberu atribútu. V prípade HT to môže byť napríklad informačný zisk (angl. information gain). Ak vypočítame priemer vzorky $\overline{r}$ potom Hoeffdingova miera hovorí, že skutočný priemer $r$ je aspoň $\overline{r}-\epsilon$ s pravdepodobnosťou $1-\delta$. Pričom $\delta$ je parameter definovaný používateľom a 
\begin{align*}
\epsilon = \sqrt{ \frac{R^2ln(1/\delta)} {2n} }
\end{align*}
HT algoritmus používa Hoeffdingovu mieru na výber najmenšieho čísla $N$ - počet vzoriek potrebných v uzle na výber rozdeľovacieho atribútu. Presnejšie, v každom uzle stromu maximalizujeme $G(A_j)$ kde funkcia G predstavuje metriku kvality atribútu $A_j$ vzorky, napríklad informačný zisk. Cieľom je nájsť najmeší počet vzoriek $N$ tak aby bola splnená Hoeffdingova miera. Nech $G(A_a)$ predstavuje atribút s najvyššou hodnotou $G$ a nech $G(A_b)$ je druhý najlepší atribút. Potom ak $G(A_a) - G(A_b) > \epsilon$ môžme s istotou tvrdiť, že rozdiel je väčší ako nula. Následne vyberieme $A_a$ ako najlepší rozdeľovací atribút v danom uzle s istotu $1-\delta$. Jediné dáta, ktoré si potrebuje HT algoritmus ukladať sú postačujúce štatistiky potrebné pre rozhodovanie a výpočet Hoeffdingovej miery, sú to počítadlá $n_ijk$ pre hodnotu $v_j$ atribútu $A_i$ z triedy $y_k$. Slabá stránka tohto algoritmu je v tom, že očakáva na vstupe prúd, ktorý neobsahuje zmeny (angl. concept-drift \citep{domingos2000mining}.
\par %TODO: pridat HFDT pseudokod
Existuje niekoľko modifikácií HT algoritmu. Tá najzákladnejšia je jeho rýchla verzia (angl. Very Fast Decision Trees, VFDT) \citep{domingos2000mining}. Modifkácia HT algoritmu, ktorá sa vie vysporiadať so zmenami v prúde sa nazýva \textit{Rýchly algoritmus pre rozhodovacie stromy adaptujúci sa na zmeny} (angl. Concept-adapting Very Fast Decision Tree, CVFDT \citep{hulten2001mining}. CVFDT používa posuvné okno, pričom nevytvára pri detekovanej zmene nový model. Namiesto toho aktualizuje postačujúce štatistiky v uzloch inkrementovaním počítadiel nových vzoriek a dekrementovaním počítadiel vzoriek, ktoré vypadli z posuvného okna. Teda, ak je v prúde dát zmena, niektoré uzly stromu nemusia viac spĺňať Hoeffdingovu mieru. Keď nastane takáto situácia, alternatívny podstrom začne narastať v uzle, ktorý nesplnil Hoeffdingovu mieru. s novými vzorkami bude alternujúci podstrom rásť, zatiaľ bez toho aby bol použitý v modeli na klasifikáciu. V momente keď sa stane alternujúci podstrom presnejší ako aktuálny, starý podstrom je nahradený alternujúcim podstromom. V algoritme je možné nastaviť hraničnú hodnotu minimálneho počtu vzoriek, ktoré musí alternujúci podstrom spracovať predtým než sa pokusí nahradiť pôvodný \citep{hulten2001mining}.
\par
Ďalšou modifikáciou HT je \textit{Adaptívny sa Hoeffdingov strom} (angl. Hoeffding Adaptive Tree) \citep{bifet2009adaptive}. Princíp je veľmi podobný ako CVFDT, ale myšlienka je minimalizovať počet parametrov, ktoré musí používateľ nastaviť (napr. veľkosť okna $W$ je požadovaný parameter CVFDT). Adaptívny HT používa rôzne 	kritéria pre odhad potrebnej veľkosti okna automaticky, napríklad algoritmus \textit{ADWIN}. S použitím tohto kritéria používateľ nemusí zadať parameter veľkosti okna čo je obrovký prínos, pretože potrebná veľkosť sa môže meniť spolu so zmenami v prúde dát. Adaptívny HT s kritériom ADWIN dosahuje v niektorých prípadoch lepšie výsledky ako CVFDT \citep{bifet2009adaptive}.
\par
Existujú aj ďalšie odlišné metódy rozhodovacích stromov, ktoré aplikujú súborové (angl. ensemble) metódy, rôzne klasifikátory v listoch ako napríklad naivný Bayes, či stromy založené na fuzzy logike \citep{aggarwal2014survey}. Náhodné lesy sú tiež použiteľné na klasifikáciu prúdov dát \citep{abdulsalam2007streaming, abdulsalam2011classification}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                Zhodnotenie                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Zhodnotenie}
Existuje mnoho problémov analýzy prúdu dát. Väčšina týchto problémov je odvodených od tých z tradičného dávkového spracovania dát. Vďaka tomu tiež väčšina algoritmov na riešenie týchto úloh a problémov rozširuje tradičné algoritmy, ako napríklad algoritmus rozhodovacích stromov pre klasifikáciu, ktorý používa Hoeffdingovu mieru pre určenie istoty výberu najlepšie atribútu pre vytvorenie rozhodovacieho uzla. Niektoré metódy do istej miery riešia problém zmien v prúde dát, avšak často len pomocou staticky nastavených parametrov používateľom. Tento prístup zlyháva, ak sa menia aj samotné zmeny, čo je častý prípad prúdov reálneho sveta.
\par
Pre lepšie pochopenie a interpretáciu modelu analytik, alebo doménový expert, často siahne po vizualizácií. Pri týchto metódách, ktorým sme sa venovali v tejto kapitole, autori takmer vôbec nevenujú pozornosť vizualizácií vzniknutého modelu. Preto považujeme tento krok v procese analýzy a spracovania dát za významný. V ďalšej kapitole analyzujeme výskum v oblasti interpretácie a vysvetlenia analytických úloh a modelov.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                									Kapitola 3 - vysvetlenie modelov									                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Prístupy vizualizácie modelov}
Vysvetlenie a prezentacia analytických modelov je kritickým komponentom pri procese analýzy dát. Je dôležité aby používateľ nevidel výsledný model len ako čiernu skrinku, ale aby bol schopný pochopiť čo viedlo k vzniku modelu. Lepšie povedané, cieľom je čo možno najjednoduchšie vysvetlenie fungovania modelu bez nutnosti znalosti všetkých detailov o fungovaní algoritmu, ktorý tvorí model. Dobrým príkladom môže byť model rozhodovacích stromov. Tento model je jednoducho a intuitívne interpretovateľný, zatiaľ čo nie je potrebná detailná znalosť rôznych algoritmov rozhodovacích stromov.
\par
Ďalšia neoddeliteľná súčasť prezentácie modelu je jeho vizuálna reprezentácia relevantná pre pochopenie používateľom. Cieľom podobných vizualizácií je nájsť rovnováhu medzi vnímaním a poznávaním a vyžiť tak všetky možnosti ľudského mozgu. Správne vysvetlenie modelu tiež zvyšuje používateľovú dôveryhodnosť vo vytvorený model \citep{Demsar2014, Barlow2001}. Vizualizácia zmeny modelu je dôležitá pre lepšie pochopenie vývoja, resp. vzniku, daného modelu. Ale tiež na prípadné spätné ladenie modelu a teda pochopenie toho, čo viedlo k zmene.
\par
Prúd dát môže byť chápaný ako sekvencia pozorovaní v čase. Výskumy zamerané na techniky vzorkovania zobrazujú dáta ako prechodný alebo dočašný komponent (angl. temporal component). V tomto kontexte vizualizácia predstavuje \textit{sumarizáciu} \citep{Demsar2014}. Zobrazovanie zmien (angl. concept drift) je další parameter, ktorý robí vizualízaciu a teda aj prezentáciu a vysvetlenie celého modelu náročnou úlohou. Aj v prípade, ak dokážeme efektívne sumarizovať dáta a zobraziť v objavené vzory, na konci stále máme problém vizualizovať zmeny. Možnosťou je použiť viac paralelných vizualizácií pre každú zmenu. Problém tohto prístupu je, že s narastajúcim počtom zmien začne byť vizualizácia neprehľadná a vediet k fenoménu známeho pod pojmom \textit{neviditeľnosť zmeny} (angl. change blindness) \citep{Demsar2014}.
\par
Adaptácia algoritmov analýzy dát na zmeny v dátach je aktívnou doménou výskumu \citep{Yao2013, pratt2003visualizing}. Napriek tomu, väčšina výskumu sa venuje extrakcii alebo detekcii zmien na úrovni dát a algoritmov. Výskum v oblasti vizualizácie modelov, ktoré sa učia a menia v reálnom čase, nad prúdmi dát stále chýba celosvetovo \citep{Yao2013}. Podľa našich vedomostí existujú len tri práce, ktoré sa priamo venujú vizualizácií zmien. V jednej práci sa venujú vizualizácií zavislostí medzi zmenami pomocou stavového diagramu resp. transformačnej mapy \citep{Yao2013}. V práci tvrdia, že väčšina algoritmov pre dolovanie a anlýzu prúdov dát používa fixnú veľkosť okna alebo bloku, do ktorých je prúd rozdeľovaný. Podľa rozdielov metrík medzi jednotlivými blokmi je detekovaná zmena. Problém tohto prístupu fixná veľkosť bloku. Pre účely vizualizácie zmien to avšak môže byť postačujúce. Distribúcia zmein je zobrazená na obrázku \ref{fig:vis-concept-distribution} at ransformačná mapa je zobrazená na obrázku \ref{fig:vis-concept-transformation-map}. Ďalším prístupom je vizualizovať zmeny v čase ich vzniku. Na obrázku \ref{fig:vviz-concept-graphs} autori vizualizujú zmenu distribúcie vybraných atribútov. Vizualizácia pomocou paralelných koordinátov bola použitá s cieľom vizualizovať zmeny kde tiež sústreďujú na vizualizáciu zmeny v distribúcií dát \citep{pratt2003visualizing}.
\myFigure{images/vis-concept-distribution}{Distribúcia zmien v prúde dát \citep{Yao2013}.}{vis-concept-distribution}{0.75}{h!}\label{fig:vis-concept-distribution}

\myFigure{images/vis-concept-transformation-map}{Mapa transformácií zmien vizualizovaná ako stavový automat \citep{Yao2013}.}{vis-concept-transformation-map}{0.65}{h!}\label{fig:vis-concept-transformation-map}

\myFigure{images/viz-concept-graphs}{Vizualizácia detekovaných zmien v čase ich vzniku \citep{Demsar2014}.}{viz-concept-graphs}{0.75}{h!}\label{fig:vviz-concept-graphs}

% zhodnotenie vizualizacii
Tieto výskumné práce sa venujú vizualizácií zmien v prúde dát a čiastočne aj ich modelov. Nedostatok týchto vizualizácií je možnosť pohľadu na vzniknutý model a to ako sa zmenil. Ďalším nedostatkom týchto vizualizácií je, že sú statické. Čo je úplne v rozpore s povahou prúdu dát a ich modelov. Problémom tiež je, že nevenujú takmer žiadnu pozornosť kvantitativnému, či expertnému vyhodnoteniu vizualizácií. Vo väčšine prác konštruujú autori vlastné závery bez používateľskej štúdie, či expertného posúdenia celej aplikácie ako celku. V tomto identifikujeme nedostatok a preto sa aj v našej práci zameriavame na vizualizáciou modelu, pričom kladieme dôraz na zobrazenie zmien modelu. Rovnako budeme venujeme značnú pozornosť na vyhodnotenie našich výsledkov aby sme mohli rozumne posúdiť použiteľnosť navrhovanej metódy. Výzvou preto ostáva jednoduchá interpretácia modelu a vizualizácia jeho zmeny v čase tak aby táto celková prezentácia ostala jednoduchá na pochopenia pre používateľa \citep{Demsar2014, Yao2013}. 







